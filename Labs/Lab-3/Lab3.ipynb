{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Lab 3: Naive Bayes and Neural Networks\"\n",
    "author: \"Chloe Feehan\"\n",
    "format: \n",
    "  html:\n",
    "    code-fold: true\n",
    "    embed-resources: true\n",
    "    toc: true\n",
    "execute:\n",
    "  message: false\n",
    "  warning: false\n",
    "theme: flatly\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Income\n",
    "\n",
    "In this lab we'll be using a dataset from kaggle yet again...it's just so fun and rich! We're using the following income dataset where we want to use the other features to predict whether someone is making over $50,000 per year or not.\n",
    "\n",
    "Primary Goals:\n",
    "\n",
    "Predict income.\n",
    "Assignment Specs:\n",
    "\n",
    "You need to use Naive Bayes and neural networks in your work to answer the question above, but you should explore at least two other models in order to answer the above questions as best you can. You may use multiple neural network models if you like, but I'd encourage you to consider past model types we've discussed.\n",
    "This dataset has variables of multiple types. So, this should give you an opportunity to explore how neural networks can (or can't) handle data of different types. You may need to one-hot encode the character variables...\n",
    "Your submission should be built and written with non-experts as the target audience. All of your code should still be included, but do your best to narrate your work in accessible ways.\n",
    "Again, submit an HTML, ipynb, or Colab link. Be sure to rerun your entire notebook fresh before submitting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income_binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt   education  education-num  \\\n",
       "0   39          State-gov   77516   Bachelors             13   \n",
       "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
       "2   38            Private  215646     HS-grad              9   \n",
       "3   53            Private  234721        11th              7   \n",
       "4   28            Private  338409   Bachelors             13   \n",
       "\n",
       "        marital-status          occupation    relationship    race      sex  \\\n",
       "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
       "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
       "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
       "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
       "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week  native-country  income_binary  \n",
       "0          2174             0              40   United-States              0  \n",
       "1             0             0              13   United-States              0  \n",
       "2             0             0              40   United-States              0  \n",
       "3             0             0              40   United-States              0  \n",
       "4             0             0              40            Cuba              0  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load in data\n",
    "income = pd.read_csv(\"income_evaluation.csv\")\n",
    "# drop nas from income column\n",
    "income.columns = income.columns.str.strip()\n",
    "income = income.dropna(subset = [\"income\"])\n",
    "# encode 1 as over 50K and 0 as less than 50K\n",
    "income['income_binary'] = income['income'].apply(lambda x: 0 if x.strip() == '<=50K' else 1)\n",
    "income = income.drop(columns = [\"income\"])\n",
    "income.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine x and y\n",
    "X = income.drop(columns = [\"income_binary\"])\n",
    "y = income[[\"income_binary\"]]\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a function that evaluates the model\n",
    "\n",
    "def evaluate_model(X, y, model_type=\"Naive Bayes\", test_size=0.2, random_state=42):\n",
    "    # Split data into train and test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    \n",
    "    # Identify categorical columns\n",
    "    cat_cols = X.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "    # Column transformer for preprocessing\n",
    "    ct = ColumnTransformer([\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols),\n",
    "        ('standardize', StandardScaler(), make_column_selector(dtype_include=np.number))\n",
    "    ])\n",
    "    \n",
    "    # List of classifiers\n",
    "    classifiers = {\n",
    "        \"Neural Network (10)\": MLPClassifier(hidden_layer_sizes=(10,), activation='relu', max_iter=500, random_state=random_state),\n",
    "        \"Neural Network (50)\": MLPClassifier(hidden_layer_sizes=(50,), activation='relu', max_iter=500, random_state=random_state),\n",
    "        \"Logistic Regression + Bagging\": BaggingClassifier(estimator=LogisticRegression(max_iter=1000), n_estimators=100),\n",
    "        \"KNN + Bagging\": BaggingClassifier(estimator=KNeighborsClassifier(n_neighbors=5), n_estimators=100),\n",
    "        \"Decision Tree + Bagging\": BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=100),\n",
    "        \"Random Forest\": RandomForestClassifier(n_estimators=100),\n",
    "        \"Stacking (LR, DT, KNN)\": StackingClassifier(estimators=[('lr', LogisticRegression(max_iter=1000)), \n",
    "                                                              ('dt', DecisionTreeClassifier()), \n",
    "                                                              ('knn', KNeighborsClassifier())]),\n",
    "    }\n",
    "\n",
    "    # Select classifier based on model_type\n",
    "    clf = classifiers[model_type]\n",
    "    pipeline = Pipeline([(\"preprocess\", ct), (\"model\", clf)])\n",
    "    \n",
    "    # Fit the model\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "\n",
    "    # Calculate accuracy and F1 score\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    # Print the results for the selected model\n",
    "    print(f\"Results for {model_type}:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chloefeehan/Desktop/python/GSB-545/gsb545_3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1124: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Neural Network (10):\n",
      "Accuracy: 0.8627\n",
      "F1 Score: 0.8588\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(X, y, model_type=\"Neural Network (10)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chloefeehan/Desktop/python/GSB-545/gsb545_3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1124: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Neural Network (50):\n",
      "Accuracy: 0.8402\n",
      "F1 Score: 0.8409\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(X, y, model_type=\"Neural Network (50)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Naive Bayes:\n",
      "Accuracy: 0.80\n",
      "F1 Score: 0.63\n"
     ]
    }
   ],
   "source": [
    "X = income.drop(columns=[\"income_binary\"])  # Features (excluding target)\n",
    "y = income['income_binary']  # Target variable\n",
    "\n",
    "cat_cols = X.select_dtypes(include='object').columns.tolist()\n",
    "ct = ColumnTransformer([\n",
    "    ('cat', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1), cat_cols)\n",
    "])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train_transformed = ct.fit_transform(X_train)\n",
    "X_test_transformed = ct.transform(X_test)\n",
    "\n",
    "nb_model = CategoricalNB()\n",
    "nb_model.fit(X_train_transformed, y_train)\n",
    "\n",
    "y_pred = nb_model.predict(X_test_transformed)\n",
    "print(f\"Results for Naive Bayes:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.2f}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, y_pred):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging\n",
    "\n",
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chloefeehan/Desktop/python/GSB-545/gsb545_3.11/lib/python3.11/site-packages/sklearn/ensemble/_bagging.py:878: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Logistic Regression + Bagging:\n",
      "Accuracy: 0.8581\n",
      "F1 Score: 0.8531\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(X, y, model_type=\"Logistic Regression + Bagging\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chloefeehan/Desktop/python/GSB-545/gsb545_3.11/lib/python3.11/site-packages/sklearn/ensemble/_bagging.py:878: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Decision Tree + Bagging:\n",
      "Accuracy: 0.8614\n",
      "F1 Score: 0.8578\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(X, y, model_type=\"Decision Tree + Bagging\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chloefeehan/Desktop/python/GSB-545/gsb545_3.11/lib/python3.11/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Random Forest:\n",
      "Accuracy: 0.8592\n",
      "F1 Score: 0.8553\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(X, y, model_type=\"Random Forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chloefeehan/Desktop/python/GSB-545/gsb545_3.11/lib/python3.11/site-packages/sklearn/preprocessing/_label.py:93: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/chloefeehan/Desktop/python/GSB-545/gsb545_3.11/lib/python3.11/site-packages/sklearn/preprocessing/_label.py:129: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Stacking (LR, DT, KNN):\n",
      "Accuracy: 0.8614\n",
      "F1 Score: 0.8566\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(X, y, model_type=\"Stacking (LR, DT, KNN)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models evaluated on the income prediction task showed varied performance. The Neural Network with 10 hidden neurons achieved the highest accuracy (0.8627) and F1 score (0.8588), closely followed by the Stacking model (Logistic Regression, Decision Tree, KNN), with an accuracy of 0.8614 and an F1 score of 0.8566. Other strong models included Random Forest and Decision Tree + Bagging, with accuracies of 0.8592 and 0.8614, respectively. The Logistic Regression + Bagging model performed slightly lower, with an accuracy of 0.8581 and an F1 score of 0.8531. The Naive Bayes model, however, performed the weakest, with an accuracy of 0.80 and an F1 score of 0.63. Overall, the neural network and ensemble models provided the best results for predicting income over $50,000, while Naive Bayes struggled due to its assumptions and the nature of the dataset."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
