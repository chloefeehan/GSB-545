{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"PA Neural Networks\"\n",
    "author: \"Chloe Feehan\"\n",
    "format: \n",
    "  html:\n",
    "    code-fold: true\n",
    "    embed-resources: true\n",
    "    toc: true\n",
    "execute:\n",
    "  message: false\n",
    "  warning: false\n",
    "theme: flatly\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Wine Price\n",
    "\n",
    "Please review the following site for information on our dataset of interest here: https://www.kaggle.com/datasets/dev7halo/wine-informationLinks to an external site.\n",
    "\n",
    "Your goal is to use the other variables in the dataset to predict wine price. Feel free to use only a subset of the variables.\n",
    "\n",
    "Assignment Specs\n",
    "\n",
    "You should compare Neural Networks as we discussed this week to at least one of our previous models from this quarter.\n",
    "A secondary goal of this assignment is to test the effects of the neural network function(s) arguments on the algorithm's performance. \n",
    "You should explore at least 5 different sets of settings for the function inputs, and you should do your best to find values for these inputs that actually change the results of your modelling. That is, try not to run three different sets of inputs that result in the same performance. The goal here is for you to better understand how to set these input values yourself in the future. Comment on what you discover about these inputs and how the behave.\n",
    "Additionally, I'd like you to include pictures of the network architecture for each of the neural network models you run. You may hand-draw them and insert pictures into your submitted files if you wish. You may also use software (e.g. draw.io) to create nice looking diagrams. I want you to become intimately familiar with these types of models and what they look like.\n",
    "Your submission should be built and written with non-experts as the target audience. All of your code should still be included, but do your best to narrate your work in accessible ways.\n",
    "Again, submit an HTML, ipynb, or Colab link. Be sure to rerun your entire notebook fresh before submitting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler, KBinsDiscretizer\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<positron-console-cell-3>:1: DtypeWarning: Columns (8,19,20) have mixed types. Specify dtype option on import or set low_memory=False.\n"
     ]
    }
   ],
   "source": [
    "wine = pd.read_csv(\"cleansingWine.csv\")\n",
    "\n",
    "# select columns\n",
    "wine = wine[[\"id\", \"name\", \"producer\", \"nation\", \"local1\", \"varieties1\", \n",
    "\"type\", \"use\", \"abv\", \"degree\", \"sweet\", \"acidity\", \"body\", \"year\", \"ml\", \"price\"]]\n",
    "\n",
    "# drop where price is zero\n",
    "wine = wine[wine[\"price\"] != 0]\n",
    "\n",
    "# convert to USD\n",
    "wine[\"price\"] = wine[\"price\"] * 0.000703"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chloefeehan/Desktop/python/GSB-545/gsb545_3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Model       MSE  R2 Score\n",
      "0  Model_1  0.466751  0.523148\n",
      "1  Model_2  0.463477  0.526493\n",
      "2  Model_3  0.458019  0.532069\n",
      "3  Model_4  0.630257  0.356104\n",
      "4  Model_5  0.467810  0.522067\n"
     ]
    }
   ],
   "source": [
    "X = wine.drop(columns=['price'])\n",
    "\n",
    "# Drop high-cardinality categorical columns\n",
    "X = X.drop(columns=['name', 'producer', 'type','acidity', 'tannin', 'year', 'ml', 'varieties1', 'varieties2'], errors='ignore')\n",
    "y = np.log1p(wine['price'])\n",
    "\n",
    "# Manually identify column types\n",
    "categorical_cols = X.select_dtypes(include='object').columns.tolist()\n",
    "numerical_cols = X.select_dtypes(include='number').columns.tolist()\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocessing transformer\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "])\n",
    "\n",
    "# Model configurations\n",
    "model_configs = [\n",
    "    {\"name\": \"Model_1\", \"hidden_layer_sizes\": (1,), \"activation\": \"relu\", \"solver\": \"adam\", \"learning_rate_init\": 0.001},\n",
    "    {\"name\": \"Model_2\", \"hidden_layer_sizes\": (5,), \"activation\": \"tanh\", \"solver\": \"adam\", \"learning_rate_init\": 0.005},\n",
    "    {\"name\": \"Model_3\", \"hidden_layer_sizes\": (10,), \"activation\": \"logistic\", \"solver\": \"sgd\", \"learning_rate_init\": 0.01},\n",
    "    {\"name\": \"Model_4\", \"hidden_layer_sizes\": (50,), \"activation\": \"relu\", \"solver\": \"lbfgs\", \"learning_rate_init\": 0.01},\n",
    "    {\"name\": \"Model_5\", \"hidden_layer_sizes\": (100,), \"activation\": \"tanh\", \"solver\": \"adam\", \"learning_rate_init\": 0.0001}\n",
    "]\n",
    "\n",
    "# Run and evaluate models\n",
    "results = []\n",
    "for config in model_configs:\n",
    "    pipe = Pipeline([\n",
    "        ('preprocess', preprocessor),\n",
    "        ('regressor', MLPRegressor(\n",
    "            hidden_layer_sizes=config['hidden_layer_sizes'],\n",
    "            activation=config['activation'],\n",
    "            solver=config['solver'],\n",
    "            learning_rate_init=config['learning_rate_init'],\n",
    "            max_iter=1000,\n",
    "            random_state=1\n",
    "        ))\n",
    "    ])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    preds = pipe.predict(X_test)\n",
    "\n",
    "    results.append({\n",
    "        \"Model\": config[\"name\"],\n",
    "        \"MSE\": mean_squared_error(y_test, preds),\n",
    "        \"R2 Score\": r2_score(y_test, preds)\n",
    "    })\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Architecture\n",
    "\n",
    "![Alt text](network-architecture.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None of the models achieved strong predictive performance, with all R² scores indicating limited ability to explain variance in wine prices. Among them, Model_3 performed the best, but even its R² of 0.53 suggests only modest predictive power.\n",
    "\n",
    "# Boosting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Model       MSE  R2 Score\n",
      "0           Model_1  0.466751  0.523148\n",
      "1           Model_2  0.463477  0.526493\n",
      "2           Model_3  0.458019  0.532069\n",
      "3           Model_4  0.630257  0.356104\n",
      "4           Model_5  0.467810  0.522067\n",
      "5  GradientBoosting  0.473744  0.516004\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Add a boosting model to the list\n",
    "boosting_model = Pipeline([\n",
    "    ('preprocess', preprocessor),\n",
    "    ('regressor', GradientBoostingRegressor(\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=3,\n",
    "        random_state=1\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Fit and evaluate\n",
    "boosting_model.fit(X_train, y_train)\n",
    "boosting_preds = boosting_model.predict(X_test)\n",
    "\n",
    "# Append results\n",
    "results.append({\n",
    "    \"Model\": \"GradientBoosting\",\n",
    "    \"MSE\": mean_squared_error(y_test, boosting_preds),\n",
    "    \"R2 Score\": r2_score(y_test, boosting_preds)\n",
    "})\n",
    "\n",
    "# Updated results DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GradientBoosting model has a similar performance to the neural network models, with an MSE of 0.473744 and an R² score of 0.516004. It performs competitively, though it doesn’t outperform the best neural network model."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
