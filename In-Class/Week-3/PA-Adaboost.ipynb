{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"PA Adaboost\"\n",
    "author: \"Chloe Feehan\"\n",
    "format: \n",
    "  html:\n",
    "    code-fold: true\n",
    "    embed-resources: true\n",
    "    toc: true\n",
    "execute:\n",
    "  message: false\n",
    "  warning: false\n",
    "theme: flatly\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should compare AdaBoost to at least one of the following: a bagging model, a stacking model. Based on the visualizations seen at the links above you're probably also thinking that this classification task should not be that difficult. So, a secondary goal of this assignment is to test the effects of the AdaBoost function arguments on the algorithm's performance. You should explore at least 3 different sets of settings for the function inputs, and you should do your best to find values for these inputs that actually change the results of your modelling. That is, try not to run three different sets of inputs that result in the same performance. The goal here is for you to better understand how to set these input values yourself in the future. Comment on what you discover about these inputs and how the behave. Your submission should be built and written with non-experts as the target audience. All of your code should still be included, but do your best to narrate your work in accessible ways. Again, submit an HTML, ipynb, or Colab link. Be sure to rerun your entire notebook fresh before submitting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pandas' has no attribute 'read_csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n",
      "\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m penguins = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m(\u001b[33m\"\u001b[39m\u001b[33mpenguins_size.csv\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[32m      2\u001b[39m penguins.dropna(inplace=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\n",
      "\u001b[31mAttributeError\u001b[39m: module 'pandas' has no attribute 'read_csv'"
     ]
    }
   ],
   "source": [
    "penguins = pd.read_csv(\"penguins_size.csv\")\n",
    "penguins.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Encode all categorical variables\n",
    "for col in penguins.columns:\n",
    "    penguins[col] = LabelEncoder().fit_transform(penguins[col])\n",
    "\n",
    "# Separate features and target\n",
    "X = penguins.drop('species', axis=1)\n",
    "Y = penguins['species']\n",
    "\n",
    "# Split into train/test sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42, stratify=Y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Model Accuracy (100 estimators, DT max_depth=5): 98.51%\n"
     ]
    }
   ],
   "source": [
    "bagging_model = BaggingClassifier(\n",
    "    estimator=DecisionTreeClassifier(max_depth=5),  # Use a deeper tree than AdaBoost\n",
    "    n_estimators=100,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "bagging_model.fit(X_train, Y_train)\n",
    "bagging_pred = bagging_model.predict(X_test)\n",
    "bagging_acc = accuracy_score(Y_test, bagging_pred)\n",
    "\n",
    "print(f\"Bagging Model Accuracy (100 estimators, DT max_depth=5): {bagging_acc * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 Accuracy (50 estimators, LR=1.0): 97.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chloefeehan/Desktop/python/GSB-545/gsb545/lib/python3.13/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model1 = AdaBoostClassifier(\n",
    "    estimator=DecisionTreeClassifier(max_depth=1),\n",
    "    n_estimators=50,\n",
    "    learning_rate=1.0,\n",
    "    algorithm='SAMME'\n",
    ")\n",
    "\n",
    "model1.fit(X_train, Y_train)\n",
    "pred1 = model1.predict(X_test)\n",
    "acc1 = accuracy_score(Y_test, pred1)\n",
    "\n",
    "print(f\"Model 1 Accuracy (50 estimators, LR=1.0): {acc1 * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2 Accuracy (200 estimators, LR=0.5): 98.51%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chloefeehan/Desktop/python/GSB-545/gsb545/lib/python3.13/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model2 = AdaBoostClassifier(\n",
    "    estimator=DecisionTreeClassifier(max_depth=1),\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.5,\n",
    "    algorithm='SAMME'\n",
    ")\n",
    "\n",
    "model2.fit(X_train, Y_train)\n",
    "pred2 = model2.predict(X_test)\n",
    "acc2 = accuracy_score(Y_test, pred2)\n",
    "\n",
    "print(f\"Model 2 Accuracy (200 estimators, LR=0.5): {acc2 * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chloefeehan/Desktop/python/GSB-545/gsb545/lib/python3.13/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 3 Accuracy (400 estimators, LR=0.1): 97.01%\n"
     ]
    }
   ],
   "source": [
    "model3 = AdaBoostClassifier(\n",
    "    estimator=DecisionTreeClassifier(max_depth=1),\n",
    "    n_estimators=400,\n",
    "    learning_rate=0.1,\n",
    "    algorithm='SAMME'\n",
    ")\n",
    "\n",
    "model3.fit(X_train, Y_train)\n",
    "pred3 = model3.predict(X_test)\n",
    "acc3 = accuracy_score(Y_test, pred3)\n",
    "\n",
    "print(f\"Model 3 Accuracy (400 estimators, LR=0.1): {acc3 * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The three AdaBoost models produced varying levels of accuracy on the test set, highlighting how different parameter choices can impact performance. Model 1, with 50 estimators and a learning rate of 1.0, achieved an accuracy of 97.01%. Model 2, which increased the number of estimators to 200 and lowered the learning rate to 0.5, performed best with an accuracy of 98.51%. Model 3 used even more estimators (400) but a much smaller learning rate of 0.1, resulting in the same accuracy as Model 1 (97.01%). These results suggest that simply increasing the number of estimators does not guarantee better performance.\n",
    "\n",
    "The Bagging model achieved 98.51% accuracy, matching AdaBoost's best result. While AdaBoost was sensitive to parameter changes, Bagging maintained strong performance with simpler tuning, demonstrating its effectiveness and stability across different settings."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "raw"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
